{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture 10\n",
    "\n",
    "## Python Parallel Computing - Part 01\n",
    "\n",
    "### Apr 5, 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Part of this lecture is based on this material from previous years: https://nyu-cds.github.io/python-mpi/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "You will need **mpi4py** \n",
    "\n",
    "To install: [https://mpi4py.readthedocs.io/en/stable/install.html](https://mpi4py.readthedocs.io/en/stable/install.html)\n",
    "\n",
    "\n",
    "Run the following in terminal: \n",
    "\n",
    "1. sudo apt install libopenmpi-dev\n",
    "\n",
    "2. pip install mpi4py\n",
    "\n",
    "\n",
    "or \n",
    "\n",
    "1. brew install open-mpi\n",
    "\n",
    "2. pip install mpi4py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Two basic approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./figs/shared_memory.png\" alt=\"shared_memory\" style=\"width: 450px;\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this is on the high level how most single computers are organized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./figs/distributed_memory.png\" alt=\"distributed_memory\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on the cluster \n",
    "- just multiple indepednt computer\n",
    "- than those comuters have some way to comunicate efficently \n",
    "- many parameters but within each parameter small operations  \n",
    "- nyu has some gpu clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelization and Amdahl's law\n",
    "\n",
    "* Want to leverage parallelization as much as possible\n",
    "* Often we cannot obtain perfect (linear) speedups, e.g., communication or global logic\n",
    "* Amdahl's law is a simple law to get an idea of the speedup:\n",
    "    - $N$: number of processors\n",
    "    - $P$: fraction of program that can be parallelized\n",
    "\n",
    "$$\n",
    "speedup = \\frac{1}{(1 - P) + \\frac{P}{N}}\n",
    "$$\n",
    "\n",
    "<img src=\"https://nyu-cds.github.io/python-mpi/fig/01-amdahls-law.png\" alt=\"amdahls\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this is the spped up we will see from parallelsm. \n",
    "- p is the fraction of the program that can be parallized. \n",
    "- this is the proprtion that can not be parallelized. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "### __MPI__ (Message Passing Interface) \n",
    "\n",
    "- Widely used standard\n",
    "\n",
    "\n",
    "- For programming **distributed-memory**, **multiple instruction**--**multiple data** (MIMD) systems\n",
    "\n",
    "\n",
    "#### __Point to point Communication__\n",
    "\n",
    "Processes should coordinate their activities by explicitly sending and receiving messages\n",
    "\n",
    "MPI operates as follows:\n",
    "- Process A decides a message needs to be sent to process B.\n",
    "- Process A packs up all of its necessary data into a buffer for process B.\n",
    "- Process A indicates that the data should be sent to process B by calling the _Send_ function.\n",
    "- Process B needs to acknowledge it wants to receive the message by calling the _Recv_ function.\n",
    "\n",
    "Every time a process sends a message, there must be a process that also indicates it wants to receive the message, therefore, calls to _Send_ and _Recv_ are always paired.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./figs/send_receive.png\" alt=\"distributed_memory\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- need a way to comunicate between processes\n",
    "- exhange messages\n",
    "- distributed memory cpu share same peac oof memory \n",
    "- muliple insturctions instructions acros smultiple jobs\n",
    "- multiple data \n",
    "point to point process a and b exhanfe memory \n",
    "- as oposed to other methods, want to specify a reciver \n",
    "- this reports a reciver that send mesasges to some other reciver \n",
    "- point to point \n",
    "- porcess a says they are going to send  amessage process b says they except to get a message from process b\n",
    "- packs up all the data put it in a buffer, which is a piece of memory \n",
    "- want to send info to b \n",
    "- b syas ok i expcet a message form a specfically\n",
    "- a could say potetinally sending mesasge from anyone \n",
    "-b says expecting mesage from anyone \n",
    "- the send and recive are always paire dtoghter. \n",
    "-  send an recive shoudl awlways be paried up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### The number of processes \n",
    "\n",
    "- Is **fixed** when an MPI program is started \n",
    "\n",
    "- Each of the processes is assigned a unique integer starting from 0. \n",
    "\n",
    "- This integer is know as the **rank** of the process and is how each process is identified when sending and receiving messages (we will refer to rank K process as \"process K\").\n",
    "\n",
    "- **MPI processes** are arranged in logical collections known as **communicators**. \n",
    "\n",
    "- There is one special communicator (**MPI.COMM_WORLD**) that exists when an MPI program starts, which contains all the processes in the MPI program. \n",
    "\n",
    "\n",
    "- MPI provides a few **methods** on a communicator:\n",
    "\n",
    "\n",
    "> Get_size() - returns the total number of processes contained in the communicator (the size of the communicator).\n",
    "\n",
    "> Get_rank() - returns the rank of the calling process within the communicator, between 0 and (size-1)\n",
    "\n",
    "> Send() - sends content to a process\n",
    "\n",
    "> Recv() - receives content from a process\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- always ahve to secpficy number of core or processors. \n",
    "- number of cores are always fixed, eahc of the process gets a unique integer called a rank. n=4 means we have 4 processes. \n",
    "- rank =0,1,2,3 if n=4\n",
    "- comunicator is a process \n",
    "- some comuncator needs to be in carhge of the whole comuncation, it needs to be the cordinator or controll that send and recives messages to make srue the worker nodes are doing there jobs. \n",
    "- get size, get rank, are just get attrbute functions \n",
    "- the most important thing is need to specficy number of cores or prcessors to use \n",
    "- each process has a unique rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libmpi.so.12: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmpi4py\u001b[39;00m \u001b[39mimport\u001b[39;00m MPI\n\u001b[1;32m      3\u001b[0m comm \u001b[39m=\u001b[39m MPI\u001b[39m.\u001b[39mCOMM_WORLD\n\u001b[1;32m      4\u001b[0m size \u001b[39m=\u001b[39m comm\u001b[39m.\u001b[39mGet_size()\n",
      "\u001b[0;31mImportError\u001b[0m: libmpi.so.12: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank() \n",
    "print('hello world: size = %d, rank = %d' % (size, rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mpi1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mpi1.py\n",
    "#####\n",
    "# writing the code in the mpi1.py file\n",
    "#####\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank() ## writing this to a file\n",
    "print('hello world: size = {}, rank = {}'.format(size, rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# running MPI from the terminal with n=4 processes\n",
    "# does not work in notebook for me for some reason, if so you can run in the terminal\n",
    "#####\n",
    "\n",
    "!mpiexec -n 4 python mpi1.py ## number of corres we use is 4. 12 cores -> 4 cores about good. number should be smaller than the number of cores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### One MPI program, multiple MPI processes\n",
    "Making each process to perform a different computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mpi2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mpi2.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "rank = MPI.COMM_WORLD.Get_rank()\n",
    "\n",
    "a = 8.0\n",
    "b = 4.0\n",
    "\n",
    "print('Process rank',rank)\n",
    "\n",
    "if rank == 0: ## difrent rnaks have difrent jobs. \n",
    "        print(\"addition:\", a + b)\n",
    "\n",
    "if rank == 1:\n",
    "        print(\"multiplication:\", a * b)\n",
    "\n",
    "if rank == 2:\n",
    "        print(\"maximum:\", max(a,b))\n",
    "        \n",
    "if rank == 3:\n",
    "        print(\"doing nothing:\")\n",
    "## makes sense. \n",
    "\n",
    "## doing things indepedntly but there is no comuncation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 4 python mpi2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Point-to-point communication\n",
    "Message passing involves two processes: a **sender** and a **receiver** (commands _Send_ and _Recv_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mpi3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mpi3.py\n",
    "#####\n",
    "# Sending a message from one process to another\n",
    "#####\n",
    "import numpy\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank() \n",
    "\n",
    "randNum = numpy.zeros(1) \n",
    "\n",
    "if rank == 1:\n",
    "        print(\"part of Process\", rank, \"- before receiving has the number\", randNum[0])\n",
    "        # generates a numpy array with one element unif. distr. from [0,1)\n",
    "        randNum = numpy.random.rand(1) ## gets random number \n",
    "        print(\"part of Process\", rank, \"- drew the number\", randNum[0])\n",
    "        comm.Send(randNum, dest=0) ## send this to rank 0\n",
    "        \n",
    "if rank == 0:\n",
    "        print(\"part of Process\", rank, \"- before receiving has the number\", randNum[0])\n",
    "        comm.Recv(randNum, source=1) ## recive the ranom number from 1 \n",
    "        print(\"part of Process\", rank, \"- received the number\", randNum[0]) ## prints that rnadom number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python mpi3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mpi4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mpi4.py\n",
    "#####\n",
    "# Sending a message to a process and receiving a message back\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1) \n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.rand(1)\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0])\n",
    "        comm.Send(randNum, dest=0)\n",
    "        comm.Recv(randNum, source=0)\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0], \"from process 0\")\n",
    "        \n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        comm.Recv(randNum, source=1)\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0], \"from process 1\")\n",
    "        randNum *= 20\n",
    "        comm.Send(randNum, dest=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figs/send_receive_mul2.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plots that we just did preetty much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python mpi4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The receiving process does not always need to specify the source when issuing a Recv.\n",
    "\n",
    "Instead, the process can accept **any message** that is being sent by another process. This is done by setting the source to **MPI.ANY_SOURCE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mpi5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mpi5.py\n",
    "#####\n",
    "# Sending a message to a process and receiving a message back from MPI.ANY_SOURCE\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1) \n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0])\n",
    "        comm.Send(randNum, dest=0)\n",
    "        comm.Recv(randNum, source=MPI.ANY_SOURCE)\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0])\n",
    "        \n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        comm.Recv(randNum, source=MPI.ANY_SOURCE) ## recivees from any source, in this case it does not matter but if had more cores. it may have difrent resuls\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0])    \n",
    "        randNum *= 2\n",
    "        comm.Send(randNum, dest=1)\n",
    "## this is "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this is a nice becuase it does not nesscarilyl assume any core. \n",
    "-  any soruc emena sodnt have to specficy a specfic destiation can make sender adn reciver nodes more genrally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python mpi5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Sometimes there are cases when a process might have to **send many different types of messages to another process**. Instead of having to go through extra measures to differentiate all these messages, MPI allows senders and receivers to also **specify message IDs (known as tags)** with the message. The receiving process can then request a message with a certain tag number and messages with different tags will be buffered until the process requests them.\n",
    "\n",
    "```python\n",
    "Comm.Send(buf, dest=0, tag=0)\n",
    "Comm.Recv(buf, source=0, tag=0, status=None)\n",
    "```\n",
    "\n",
    "The _status_ can provide useful information\n",
    "```python\n",
    "info = MPI.Status()\n",
    "source = info.Get_source()\n",
    "tag = info.Get_tag()\n",
    "count = info.Get_elements()\n",
    "size = info.Get_count()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tag is like a message identfier, want to make sure data 1 recives data 1 and data 2 recives data 2. \n",
    "- makes sure messages are mapped to write worker node. \n",
    "- tags shuld be numbers but dont nessacarilyl haveo to b consecutive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mpi_tag.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mpi_tag.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank() \n",
    "\n",
    "data1 = None\n",
    "data2 = None\n",
    "\n",
    "if rank == 0:\n",
    "    data1 = ('a','b', 'c', 'd')\n",
    "    data2 = (1, 2, 3, 4)\n",
    "    \n",
    "    comm.send(data1, dest=1, tag=0)    \n",
    "    comm.send(data2, dest=1, tag=1)\n",
    "    \n",
    "    \n",
    "\n",
    "elif rank == 1:\n",
    "    print('On Process',rank,'before recv: data1 = ', data1)\n",
    "    print('On Process',rank,'before recv: data2 = ', data2)\n",
    "    \n",
    "    data1 = comm.recv(source=0, tag=0)  \n",
    "    data2 = comm.recv(source=0, tag=1)\n",
    "    \n",
    "    print('On Process',rank,'after  recv: data1 = ', data1)\n",
    "    print('On Process',rank,'after  recv: data2 = ', data2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python mpi_tag.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mpi_status.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mpi_status.py\n",
    "#####\n",
    "# Sending a message from one process to another\n",
    "#####\n",
    "\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "info = MPI.Status() ## ubtukuze stats function prints info \n",
    "print(\"info: \", info)\n",
    "\n",
    "randNum = numpy.zeros(1) ## stuf fup gere sis run ever time. \n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0]) ## just drwas and send a random number,\n",
    "        comm.Send(randNum, dest=0) \n",
    "\n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        comm.Recv(randNum, source=1, status=info)\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0], \"from Process\", info.Get_source()) ## recives the info then, also writes stats into inof and prints out the source. \n",
    "        ## if you have more core can tell where something came from if something crashed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python mpi_status.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Non-blocking Communication\n",
    "\n",
    "In the previous examples, the sender and receiver are not able to perform any action when sending or receiving a message. This can waste computation time while waiting for the call to complete. \n",
    "\n",
    "__Non-blocking communcation__ avoids this issue by using the _Isend_ and _Irecv_ methods, which start to send and receive operations and _then return immediately to continue computation_.\n",
    "\n",
    "The completion of a send or receive operation can be managed using the _Test_, _Wait_, and _Cancel_ methods.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in previous stuff if calll send but not recive we get stuck that is called blocking comuncation \n",
    "- then we can have non-blocking comuncation, which send even if soemthing is not recives.  have isend and irecive functions. \n",
    "- wait just makees the process wait for a second kinda like a blocking thing. \n",
    "- test keeps trying until it is sucessfull \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mpi6.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mpi6.py\n",
    "\n",
    "# this code is similar to mpi3.py, \n",
    "# but it uses Wait to block the processes\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1)\n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0])\n",
    "        \n",
    "        req = comm.Isend(randNum, dest=0)\n",
    "       # req.Wait() ## just having this one will make it 100% wrong. \n",
    "        ## wait only really makes sense when we are reciving something. when ever things are done asynchonalsly want to make sure you are not modifying hte same piece of data at teh same time.\n",
    "        print('something here')\n",
    "        \n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        \n",
    "        req = comm.Irecv(randNum, source=1) ## might not be recived it will just move on. this gives you flexability but want to be carefull. \n",
    "        #req.Wait() ## if wait here that will not move on with out it. \n",
    "        while not req.Test():\n",
    "                print(\"waiting\")\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python mpi6.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap communication\n",
    "\n",
    "\n",
    "**Example:** Process 1 overlaps a computation with sending the message and receiving the reply. The computation divides randNum by 10 and prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mpi7.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mpi7.py\n",
    "#####\n",
    "# overlap communication\n",
    "#####\n",
    "\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1) \n",
    "\n",
    "if rank == 1:\n",
    "#         randNum = numpy.random.random_sample(1)\n",
    "        randNum = numpy.array([50], dtype=numpy.float64) ## makes the number specfic instead of random\n",
    "        print(\"Process\", rank, \"drew the number\", randNum[0]) ## drew the number which will always b 50\n",
    "        \n",
    "        comm.Isend(randNum, dest=0) ## i send this to zero \n",
    "         \n",
    "        randNum[0] /= 10 # overlap communication ## do some data modivaction not caring about what rank data has recived\n",
    "        print(\"Process\", rank, \"number in overlap communication =\", randNum[0]) ## \n",
    "         \n",
    "        req = comm.Irecv(randNum, source=0)\n",
    "        req.Wait()\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0]) ## should out put the input devided by 5\n",
    "\n",
    "if rank == 0:\n",
    "        print(\"Process\", rank, \"before receiving has the number\", randNum[0])\n",
    "        req = comm.Irecv(randNum, source=1) ## i recive from the other thing \n",
    "        req.Wait()\n",
    "        print(\"Process\", rank, \"received the number\", randNum[0]) \n",
    "        randNum *= 2 ## then we multiply by 2 qne w3ne it back\n",
    "        comm.Isend(randNum, dest=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec -n 2 python mpi7.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
