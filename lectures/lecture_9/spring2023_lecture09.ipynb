{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture 9: Python Concurrency\n",
    "### March 29, 2023\n",
    "\n",
    "Partly based on [https://nyu-cds.github.io/python-concurrency/](https://nyu-cds.github.io/python-concurrency/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Improving performance by using concurrency\n",
    "\n",
    "Concurrency vs parallelism:\n",
    "\n",
    "    Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once.\n",
    "    \n",
    "[source](https://medium.com/@itIsMadhavan/concurrency-vs-parallelism-a-brief-review-b337c8dac350)\n",
    "- the link does a good job \n",
    "- concurency is about dealing with difrent things at once but does not nessvarilly have to be involved with wokring on both tasks all at once \n",
    "- u have 2 tasks, you can be working on them togther, but at each time you do not have to be working on both, like you could be rotating between the two at difrenet time steps\n",
    "- parallism means you are doing two tasks at the same time, so that requires mutliple cpu cores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will illustrate some benefits of concurrency with a program downloading images from the `imgur.com` website.\n",
    "\n",
    "For this you will need to:\n",
    "\n",
    "- create an account in [imgur.com](https://imgur.com/)\n",
    "- register your application [here](https://api.imgur.com/oauth2/addclient)\n",
    "  - Authorization Type: __OAuth 2 authorization with a callback URL__\n",
    "  - Authorization Callback URL: __https://www.getpostman.com/oauth2/callback__\n",
    "  - email:\n",
    "  - Description:\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "The functions below fetchs a list of images and download them __imgur__ repository: \n",
    "[https://imgur.com/](https://imgur.com/)\n",
    "\n",
    "- We will start with a version that downloads images sequentially, or one at a time\n",
    "\n",
    "- Then improve the performance by introducing multiprocessing and threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "We will split the functionality into three separate functions, see the file `download.py`\n",
    "- get_links\n",
    "- download_link\n",
    "- setup_download_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 http://i.imgur.com/dpB8Sh0h.gif\n",
      " 1 https://i.imgur.com/dpODH.jpg\n",
      " 2 https://i.imgur.com/dptSVFW.jpg\n",
      " 3 https://i.imgur.com/dpXGCE2.gif\n",
      " 4 https://i.imgur.com/dpqvtZv.jpg\n",
      " 5 https://i.imgur.com/dpssv.gif\n",
      " 6 https://i.imgur.com/dpjwyc4.png\n",
      " 7 https://i.imgur.com/dpzvDV8.jpg\n",
      " 8 http://i.imgur.com/dpKlbMBh.gif\n",
      " 9 https://i.imgur.com/dpe2z.jpg\n",
      "10 https://i.imgur.com/dpnlmJz.jpg\n",
      "11 https://i.imgur.com/dp48Om4.jpg\n",
      "12 https://i.imgur.com/dpnj7F8.gif\n",
      "Took 3.079061269760132s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# 'replace with your client ID'\n",
    "CLIENT_ID = '989ced793a1b0ef'\n",
    "from download import setup_download_dir, get_links, download_link\n",
    "\n",
    "ts = time()\n",
    "download_dir = setup_download_dir()\n",
    "\n",
    "links = [l for l in get_links(CLIENT_ID)]\n",
    "\n",
    "for i, link in enumerate(links):\n",
    "    print(\"%2d %s\" % (i, link))\n",
    "    download_link(download_dir, link)\n",
    "\n",
    "print('Took {}s'.format(time() - ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35mdp48Om4.jpg\u001b[0m   \u001b[01;35mdpODH.jpg\u001b[0m    \u001b[01;35mdpjwyc4.png\u001b[0m  \u001b[01;35mdpqvtZv.jpg\u001b[0m  \u001b[01;35mdpzvDV8.jpg\u001b[0m\n",
      "\u001b[01;35mdpB8Sh0h.gif\u001b[0m  \u001b[01;35mdpXGCE2.gif\u001b[0m  \u001b[01;35mdpnj7F8.gif\u001b[0m  \u001b[01;35mdpssv.gif\u001b[0m\n",
      "\u001b[01;35mdpKlbMBh.gif\u001b[0m  \u001b[01;35mdpe2z.jpg\u001b[0m    \u001b[01;35mdpnlmJz.jpg\u001b[0m  \u001b[01;35mdptSVFW.jpg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- To improve the performance of the image downloader we can run **multiple copies** of the program at the same time. \n",
    "\n",
    "\n",
    "- However, we would need to know what images are available so that we could ensure that one process didnâ€™t download an image that had already been downloaded by a different process.  \n",
    "\n",
    "\n",
    "- Fortunately the multiprocessing module is available for this purpose.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- how can we decrease the amount of times it takes to download an image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool\n",
    "\n",
    "- To use multiple processes we need a multiprocessing **Pool**. \n",
    "\n",
    "\n",
    "- The Pool class provides a map method that runs a function as a separate process, passing arguments from a supplied iterable. \n",
    "\n",
    "\n",
    "- The iterable is divided into a number of chunks, so that each process gets roughly the same number of elements. \n",
    "\n",
    "\n",
    "- We will pass the list of URLs to the pool, which starts 8 new processes and use each one to download the images in parallel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- here we are effectivly jsut running many version of the same code at once. \n",
    "- want to make sure that you are not downloading immages, twice so want to use multiprocessing module, lets them run the same code multiple times with out repeated work \n",
    "- pool is a map method \n",
    "- to use it we have this function downlaod links and directories where they should go, and this is itterable. \n",
    "- we have this funciton downlaod link and then we suply our link thne id \n",
    "- the iterable is devided into the number of ellements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "print(\"number of CPU cores:\", cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 59.33877372741699s\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "def multi_processes_download():\n",
    "    ts = time()\n",
    "    download_dir = setup_download_dir() ## irweBLW\n",
    "    links = [l for l in get_links(CLIENT_ID)]\n",
    "\n",
    "    # functools.partial makes a new version of a function \n",
    "    # with one or more fixed arguments\n",
    "    download = partial(download_link, download_dir) ##  makes a copt of this function\n",
    "   \n",
    "    with Pool(8) as p: ## this sets the number of cores you are running. \n",
    "        p.map(download, links) ## map download to link\n",
    "        \n",
    "    print('Took {}s'.format(time() - ts)) ## \n",
    "\n",
    "multi_processes_download() ## this reduce the  time the factor of 8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "Although easy to implement, the parallelism bears some drawbacks:\n",
    "- each process contains **a copy of the entire memory**\n",
    "- it does not handle processes that depend on each other\n",
    "\n",
    "Those issues can be tackled by shared memory and message passing mechanisms, which we will learn from later lessons."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this does not handle processes with dependicies, things can be really well devided w\n",
    "- processes that have dependinces on one another can be dealt with in a later class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using Threads\n",
    "\n",
    "Threading is a well known approach to attaining concurrency: \n",
    "- typically threads are lighter weight than processes\n",
    "- **lower memory requirements**, as **they share the same memory space**\n",
    "\n",
    "A basic way to use threads is through `ThreadPoolExecutor` in `concurrent.futures`, which provides a similar interface to `multiprocessing.Pool`.\n",
    "\n",
    "For more refined behavior will rely on the `Thread` class, which provides a `run` method that should be overridden with a method that does the actual work of the thread."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple example with ThreadPoolExecutor\n",
    "\n",
    "from functools import partial \n",
    "from concurrent.futures import ThreadPoolExecutor \n",
    "\n",
    "def multithreaded_download():\n",
    "    ts = time()\n",
    "    download_dir = setup_download_dir()\n",
    "    links = [l for l in get_links(CLIENT_ID)]\n",
    "\n",
    "    download = partial(download_link, download_dir) ## partial sets an arugmnet \n",
    "   \n",
    "    with ThreadPoolExecutor(max_workers=8) as ex:\n",
    "        ex.map(download, links)\n",
    "        \n",
    "    print('Took {}s'.format(time() - ts))\n",
    "\n",
    "multithreaded_download()\n",
    "## this may not lead to memory improvemts but will likely lead to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Thread Safety\n",
    "\n",
    "- Variables in the program are shared by all the threads and should not be accessed the way you would normally access a variable. One thread may change the variable while another thread is reading it, or worse, two threads may try to update the variable at the same time. \n",
    "\n",
    "\n",
    "- This is known as a **race condition**, it is one of the leading sources of errors in threaded programs and needs to be addressed properly.\n",
    "\n",
    "\n",
    "\n",
    "- A way to deal with thread safety is using the __Queue Class__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in the image downloading example, it is not really a concern\n",
    "- but if you are not carefulll about how you access shared varible there could be erorrs\n",
    "- didiferent threads could be racing to change a certain varible \n",
    "- one way to deal with it is to use a que. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Understanding Queue \n",
    "from queue import Queue \n",
    "\n",
    "def do_work(q): ## uf the q if not empry you get a n item print the string veriosn of the item and then run it on teh taks \n",
    "    while not q.empty():\n",
    "        item = q.get()\n",
    "        print(str(item)) \n",
    "        q.task_done()  # this is important when combining Queue with Threads\n",
    "\n",
    "q = Queue() # FIFO queue\n",
    "\n",
    "for i in range(20):\n",
    "    q.put(i)\n",
    "\n",
    "do_work(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simpler example before going back to the image downloader code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this example each thread prints an element of the queue\n",
    "\n",
    "from time import sleep\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import logging  \n",
    "\n",
    "# set up a logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(format='(%(threadName)-9s) %(message)s', level=logging.DEBUG)\n",
    "\n",
    "def do_work(q):\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        logger.debug(\"e\" + str(item) + ' ')\n",
    "        print(str(item) + ' ')\n",
    "        q.task_done()\n",
    "        sleep(2)\n",
    "    \n",
    "q = Queue()\n",
    "num_threads = 10 ## 10 threads\n",
    "\n",
    "for i in range(num_threads):\n",
    "    worker = Thread(target=do_work, args=(q,), name='thread_' + str(i)) ## worker \n",
    "    worker.setDaemon(True) # this stop the threads when the program quits  \n",
    "    worker.start()         # start the threads\n",
    "\n",
    "# now we have started 10 threads:\n",
    "\n",
    "for i in range(50): #3 50 taks , in chunks of 10. , the order depends on when the task finishes. \n",
    "    q.put(i)\n",
    "\n",
    "q.join() # wait until all threads have finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "class DownloadWorker(Thread):\n",
    "    def __init__(self, queue):\n",
    "        super(DownloadWorker, self).__init__()\n",
    "        self.queue = queue\n",
    "    \n",
    "    def run(self):\n",
    "        while True:\n",
    "            # Get the work from the queue and expand the tuple\n",
    "            (directory, link) = self.queue.get()\n",
    "            # call the function donwload_link (from download.py)\n",
    "            download_link(directory, link)\n",
    "            self.queue.task_done()\n",
    "\n",
    "            \n",
    "def threaded_download():\n",
    "    ts = time()\n",
    "    download_dir = setup_download_dir()\n",
    "    links = [l for l in get_links(CLIENT_ID)]\n",
    "    \n",
    "    # Create a queue to communicate with the worker threads\n",
    "    queue = Queue()\n",
    "    \n",
    "    # Create 8 worker threads\n",
    "    for _ in range(8):\n",
    "        worker = DownloadWorker(queue)\n",
    "        # Setting daemon to True will let the main thread exit \n",
    "        # even if the workers are blocking\n",
    "        worker.daemon = True\n",
    "        worker.start()\n",
    "\n",
    "    \n",
    "    # Put the tasks into the queue as a tuple\n",
    "    for link in links:\n",
    "        print('Queueing: {}'.format(link))\n",
    "        queue.put((download_dir, link))\n",
    "    \n",
    "    # Causes the main thread to wait for the queue to finish processing all the tasks\n",
    "    queue.join()\n",
    "    \n",
    "    print('Took {}s'.format(time() - ts))\n",
    "\n",
    "threaded_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Global Interpreter Lock\n",
    "#### Not really parallel !\n",
    "\n",
    "- Python has a **Global Interpreter Lock (GIL)**, which allows only **one thread to be executed at a time** throughout this process. Therefore, **this code is concurrent but not parallel**. \n",
    "\n",
    "- The reason it is still faster is because the image downloader is an input/output (I/O) bound task. \n",
    "The majority of the time is spent waiting for the network. This is why threading can provide a large speed increase. \n",
    "\n",
    "- **The processor can switch between the threads** whenever one of them is **ready** to do some work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "- If the program was performing a task that was CPU bound, using the threading module in Python or any other interpreted language with a GIL could actually result in reduced performance.\n",
    "\n",
    "- For CPU bound tasks and truly parallel execution in Python, the multiprocessing module is a better option.\n",
    "\n",
    "- Some parallelism is still possible with threads if the executed functions rely on low-level code that realeases the GIL (e.g. many Numpy/Scipy functions). This includes custom Cython programs (see the `nogil` keyword [here](https://cython.readthedocs.io/en/latest/src/userguide/parallelism.html) and [here](https://cython.readthedocs.io/en/latest/src/userguide/numpy_tutorial.html))\n",
    "\n",
    "- Other packages for parallelization: task/job queues (e.g. [python-rq](https://python-rq.org/)), [joblib](https://joblib.readthedocs.io/en/latest/parallel.html), [dask](https://dask.org/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- python has gil, it only allows one thread to be executed at a time. so it can be concurecnt but not parallel\n",
    "- if you use c++ or c, that is not as much an issue \n",
    "- immage downloading is often more a function of waiting on the network than the core. \n",
    "- tha tis an input output bounds task \n",
    "- a cpu bound task is something that is pure computuation, so does not invovle acessing memoery or what ever. \n",
    "- multi processing is a better option for cpu bound tasks. \n",
    "- for cpu bound tasks you really have to do the work . \n",
    "- the gil is a big draw back of pyhton, evetything has to be concurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Example: sum of array elements in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999999950000000 --> 9.527128458023071 s\n"
     ]
    }
   ],
   "source": [
    "# Sequential version\n",
    "from time import time\n",
    "\n",
    "ts = time()\n",
    "s = 0\n",
    "for i in range(n):\n",
    "    s = s + i\n",
    "print(s, '-->', time()-ts,'s')   \n",
    "\n",
    "## this is a function taht ads from zero to 10 tehe 8thh adn says how ong tha ttakes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this is a cpu bound task so multi process is a good task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 chunks\n",
      "4999999950000000 --> 11.718096494674683 s\n"
     ]
    }
   ],
   "source": [
    "# multiprocessing version\n",
    "from time import time\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "from download import sum_multi_processes_1, sum_multi_processes_2\n",
    "\n",
    "def sum_multi_processes_1_(chunk):\n",
    "    y = 0\n",
    "    for i in chunk:\n",
    "        y = y + i\n",
    "    return y\n",
    "## both add things up given chunk??\n",
    "# the second one uses the range function \n",
    "# the first one has a loop\n",
    "## so it is teh difernce between an itteator the and the list\n",
    "## the ssecond is going to be fast then. \n",
    "\n",
    "def sum_multi_processes_2_(start, end):\n",
    "    y = 0\n",
    "    for i in range(start, end):\n",
    "        y = y + i\n",
    "    return y\n",
    "\n",
    "chunks1 = [list(range(i,i + 100)) for i in range(0, n, 100)]\n",
    "chunks2 = [(i,i + 100) for i in range(0, n, 100)]\n",
    "\n",
    "print(len(chunks1), 'chunks')\n",
    "\n",
    "ts = time()\n",
    "with Pool(8) as p:\n",
    "     results = p.map(sum_multi_processes_1, chunks1)\n",
    "#     results = p.starmap(sum_multi_processes_2, chunks2)\n",
    "\n",
    "print(sum(results), '-->', time()-ts,'s')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread version\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "\n",
    "x = 0\n",
    "lock = Lock()\n",
    "def sum_chunk(q):\n",
    "    while True:\n",
    "        global x\n",
    "        start, end = q.get()\n",
    "        for i in range(start, end):\n",
    "            with lock:  # force synchronization\n",
    "                x = x + i\n",
    "        q.task_done()\n",
    "\n",
    "n = int(1e8)\n",
    "chunks = [(i, i + 100) for i in range(0, n, 100)]\n",
    "\n",
    "ts = time()\n",
    "q = Queue()\n",
    "num_threads = 10\n",
    "\n",
    "for i in range(num_threads):\n",
    "    worker = Thread(target=sum_chunk, args=(q, ))\n",
    "    worker.setDaemon(True) # this stop the threads when the program quits  \n",
    "    worker.start()         # start the threads\n",
    "\n",
    "for chunk in chunks:\n",
    "    q.put(chunk)\n",
    "\n",
    "q.join()\n",
    "print(x, '-->', time() - ts, 's')    \n",
    "## here we are trying a trheaded version of the same code\n",
    "# play around with th epool number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Pi Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download import monte_carlo_pi\n",
    "import numpy as np\n",
    "\n",
    "def monte_carlo_pi_(n):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        x = np.random.uniform(0, 1)\n",
    "        y = np.random.uniform(0, 1)\n",
    "        if (x**2 + y**2) < 1:\n",
    "            s += 1\n",
    "    return 4*s/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = [monte_carlo_pi(int(3e5)) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Pool(8) as pool:\n",
    "    result = pool.map(monte_carlo_pi, [int(3e5) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
